{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Variational AutoEncoders (VAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to demonstrate how VAEs work in practice through a coding example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download a utils.py file containing some utility functions we will need\n",
    "!curl -O https://raw.githubusercontent.com/chimie-paristech-CTM/PSL_notebooks/main/generative_models/utils.py\n",
    "!curl -O https://raw.githubusercontent.com/chimie-paristech-CTM/PSL_notebooks/main/generative_models/pretrained.zinc.rnn.pth\n",
    "# download the pre-trained VAE model\n",
    "!curl -O https://raw.githubusercontent.com/chimie-paristech-CTM/PSL_notebooks/main/generative_models/pretrained.vae.pt\n",
    "# clone repository to extract the compressed molecular data\n",
    "!git clone https://github.com/aksub99/molecular-vae.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install other packages required\n",
    "!pip install rdkit\n",
    "!pip install molplotly\n",
    "!pip install torch==2.1\n",
    "!pip install numpy==1.26\n",
    "!pip install scikit-learn\n",
    "!pip install h5py\n",
    "!pip install dash==2.9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by presenting a high-level overview of VAEs (figure below was taken from [here](https://towardsdatascience.com/vae-variational-autoencoders-how-to-employ-neural-networks-to-generate-new-images-bdeb216ed2c0)).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"middle\">\n",
    "<img src=\"https://towardsdatascience.com/wp-content/uploads/2022/04/1qtXrzMLorYDl4SzKqoZxBg-1536x1110.png\" width=\"900\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As already explained during the lecture, the `Encoder` takes molecules and converts it into a low-dimensional vector. The job of the `Decoder` is to take this `Latent Vector` and `reconstruct` the input.\n",
    "\n",
    "In practice, to enable robust introduction of noise (which is an essential element of the VARIATIONAL autoencoder), the latent vectors are typically mapped onto a `Gaussian Distribution`, i.e., we don't actually assign the molecule to just a single point, but we assign a probabilistic distribution to them. \n",
    "\n",
    "`Gaussian Distributions` or `Normal Distributions`  are completely defined by their `mean` and `variance`, which means that if you know both the `mean` and `variance`, you can construct the full `Gaussian Distribution`. \n",
    "\n",
    "When every molecule is assigned a `mean` and `variance`, then the noise can be added according to the formula provided in the figure. The noise parameter `epsilon` is typically drawn from a `Gaussian Distribution` itself. \n",
    "\n",
    "In the [original molecular `VAE` paper](https://pubs.acs.org/doi/10.1021/acscentsci.7b00572), a neural network model was trained to predict properties in the `Latent Space`. Additionally, it was demonstrated how you can move in the `Latent Space` to go from some starting molecule to another molecules with desired properties. Here, we omit further details and instead try to visually demonstrate what the `Latent Space` is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the `VAE` code below is taken from [here](https://aksub99.github.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import gzip\n",
    "import pandas\n",
    "import h5py\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import h5py\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are utility functions\n",
    "def one_hot_array(i, n):\n",
    "    return map(int, [ix == i for ix in xrange(n)])\n",
    "\n",
    "def one_hot_index(vec, charset):\n",
    "    return map(charset.index, vec)\n",
    "\n",
    "def from_one_hot_array(vec):\n",
    "    oh = np.where(vec == 1)\n",
    "    if oh[0].shape == (0, ):\n",
    "        return None\n",
    "    return int(oh[0][0])\n",
    "\n",
    "def decode_smiles_from_indexes(vec, charset):\n",
    "    return b\"\".join(map(lambda x: charset[x], vec)).strip()\n",
    "\n",
    "def load_dataset(filename, split = True):\n",
    "    h5f = h5py.File(filename, 'r')\n",
    "    if split:\n",
    "        data_train = h5f['data_train'][:]\n",
    "    else:\n",
    "        data_train = None\n",
    "    data_test = h5f['data_test'][:]\n",
    "    charset =  h5f['charset'][:]\n",
    "    h5f.close()\n",
    "    if split:\n",
    "        return (data_train, data_test, charset)\n",
    "    else:\n",
    "        return (data_test, charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main code for the VAE is found below\n",
    "class MolecularVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # encoder related blocks\n",
    "        # 120 corresponds to the default size selected for the SMILES string (if the string contains less tokens, the remaining entries are left \"empty\")\n",
    "        # for every token, there are 33 options, i.e., every SMILES string is turned into a matrix/tensor of shape [120, 33]\n",
    "        # for the first index of the tensor, we go from 120 to 9 dimensions in the first convolutional layer. For the second index, \n",
    "        # we gradually reduce the size based on the kernel size. \n",
    "        self.conv_1 = nn.Conv1d(120, 9, kernel_size=9) \n",
    "        self.conv_2 = nn.Conv1d(9, 9, kernel_size=9)\n",
    "        self.conv_3 = nn.Conv1d(9, 10, kernel_size=11)\n",
    "        self.linear_0 = nn.Linear(70, 435)\n",
    "        self.linear_1 = nn.Linear(435, 292)\n",
    "        self.linear_2 = nn.Linear(435, 292)\n",
    "\n",
    "        # decoder related blocks\n",
    "        # now we go back from 292 dimensions to the original size of the molecule\n",
    "        self.linear_3 = nn.Linear(292, 292)\n",
    "        self.gru = nn.GRU(292, 501, 3, batch_first=True)\n",
    "        self.linear_4 = nn.Linear(501, 33)\n",
    "\n",
    "        # activation function \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def encode(self, x):\n",
    "        # forward pass through encoder\n",
    "        x = self.relu(self.conv_1(x)) # input shape [120, 33], output shape [9, 25] \n",
    "        x = self.relu(self.conv_2(x)) # input shape [9, 25], output shape [9, 17]\n",
    "        x = self.relu(self.conv_3(x)) # input shape [9, 17], output shape [10, 7]\n",
    "        x = x.view(x.size(0), -1) # turns the [10, 7] tensor into a [70] one\n",
    "        x = F.selu(self.linear_0(x))\n",
    "        return self.linear_1(x), self.linear_2(x)\n",
    "\n",
    "    def sampling(self, z_mean, z_logvar):\n",
    "        # recall in the VAE figure, noise is added\n",
    "        # epsilon is the noise\n",
    "        epsilon = 1e-2 * torch.randn_like(z_logvar)\n",
    "        # return the latent vector (this is what the decoder will use to reconstruct the input)\n",
    "        return torch.exp(0.5 * z_logvar) * epsilon + z_mean\n",
    "\n",
    "    def decode(self, z):\n",
    "        # forward pass through decoder to go from latent vector back to a molecule\n",
    "        z = F.selu(self.linear_3(z))\n",
    "        z = z.view(z.size(0), 1, z.size(-1)).repeat(1, 120, 1)\n",
    "        output, hn = self.gru(z)\n",
    "        out_reshape = output.contiguous().view(-1, output.size(-1))\n",
    "        y0 = F.softmax(self.linear_4(out_reshape), dim=1)\n",
    "        y = y0.contiguous().view(output.size(0), -1, y0.size(-1))\n",
    "        return y\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the overall forward pass takes the input, passes it to the encoder and then decoder\n",
    "        # first encode your input to get the mean and variance of the Gaussian distribution it is mapped to\n",
    "        z_mean, z_logvar = self.encode(x)\n",
    "        # get the latent vector taking the mean and variance above and adding noise t it\n",
    "        z = self.sampling(z_mean, z_logvar)\n",
    "        # decode the latent vector, z, to reconstruct a molecule\n",
    "        return self.decode(z), z_mean, z_logvar\n",
    "    \n",
    "def vae_loss(x_decoded_mean, x, z_mean, z_logvar):\n",
    "    # the loss function is a combination of 2 quantities:\n",
    "    #     1. \"reconstruction loss\" which measures how different the reconstructed molecule \n",
    "    #        is to the original. We would want them to be similar\n",
    "    \n",
    "    #     2. \"Kullbackâ€“Leibler (KL) divergence\". We are trying to approximate the distribution\n",
    "    #         of the latent vector with a Gaussian distribution. The KL divergence measure how \"off\" we are\n",
    "    reconstruction_loss = F.binary_cross_entropy(x_decoded_mean, x, size_average=False)\n",
    "    kl_loss = -0.5 * torch.sum(1 + z_logvar - z_mean.pow(2) - z_logvar.exp())\n",
    "    return reconstruction_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip molecular-vae/data/processed.zip  -d molecular-vae/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was used when we pre-trained the VAE\n",
    "# it initializes a PyTorch DataLoader so we can read batches of molecules at a time during training\n",
    "data_train, data_test, charset = load_dataset('molecular-vae/data/processed.h5')\n",
    "data_train = torch.utils.data.TensorDataset(torch.from_numpy(data_train))\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=500, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate an instance of the MolecularVAE \n",
    "pretrained_vae = MolecularVAE()\n",
    "# load the pre-trained model (we provide this)\n",
    "pretrained_vae.load_state_dict(torch.load('pretrained.vae.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Starting* below, we will visualize the `Latent Space`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RERUN HERE FOR NEW MOLECULES!\n",
    "# this bit of code randomly takes 500 molecules from the training data\n",
    "for batch in train_loader:\n",
    "    training_data_molecules = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually add some noise to the training data molecules --> we will see \n",
    "# what these \"noised\" molecules look like in the latent space later\n",
    "num_noised = 10\n",
    "molecules_to_noise = training_data_molecules[0][:num_noised]\n",
    "\n",
    "# you can check that molecules_to_noise is a tensor with a shape of [10, 120, 33], i.e., number of molecules, default token length, types of tokens\n",
    "print(molecules_to_noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we add noise to every element of this tensor\n",
    "noised_molecules = molecules_to_noise + torch.normal(0, 0.0001, (num_noised, 120, len(charset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this bit of code gets the SMILES back from the 500 training data molecules we got above\n",
    "smiles_list = []\n",
    "for idx in range(training_data_molecules[0].shape[0]):\n",
    "    vector = training_data_molecules[0][idx].reshape(1, 120, len(charset)).argmax(axis=2)[0]\n",
    "    smiles = decode_smiles_from_indexes(vector, charset)\n",
    "    smiles = str(smiles).replace(\"'\", '').replace('b', '')\n",
    "    smiles_list.append(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this bit of code gets the SMILES from the \"noised\" training data molecules\n",
    "noised_smiles_list = []\n",
    "for idx in range(noised_molecules.shape[0]):\n",
    "    vector = noised_molecules[idx].reshape(1, 120, len(charset)).argmax(axis=2)[0]\n",
    "    smiles = decode_smiles_from_indexes(vector, charset)\n",
    "    smiles = str(smiles).replace(\"'\", '').replace('b', '')\n",
    "    noised_smiles_list.append(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the training data SMILES\n",
    "z_mean, z_logvar = pretrained_vae.encode(training_data_molecules[0])\n",
    "# get the latent space\n",
    "latent_space = pretrained_vae.sampling(z_mean, z_logvar)\n",
    "\n",
    "# encode the noised data\n",
    "noised_z_mean, noised_z_logvar = pretrained_vae.encode(noised_molecules)\n",
    "# get the latent space of the \"noised\" molecules\n",
    "noised_latent_space = pretrained_vae.sampling(noised_z_mean, noised_z_logvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code here plots an interative (cross-section of the) latent space - hover around the space and explore the molecules!\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import molplotly\n",
    "import pandas as pd \n",
    "\n",
    "all_smiles = smiles_list + noised_smiles_list\n",
    "full_latent_space = torch.vstack([latent_space, noised_latent_space])\n",
    "\n",
    "print(full_latent_space)\n",
    "\n",
    "plotting_df = pd.DataFrame({'smiles': all_smiles,\n",
    "                           'group': ['Training Data']*500 + ['Sampled from Latent Space']*num_noised,\n",
    "                           'latent_space_x': full_latent_space[:, 0].detach(),\n",
    "                           'latent_space_y': full_latent_space[:, 1].detach()})\n",
    "\n",
    "fig_scatter = px.scatter(plotting_df,\n",
    "                         x='latent_space_x',\n",
    "                         y='latent_space_y',\n",
    "                         color='group')\n",
    "\n",
    "app_scatter = molplotly.add_molecules(fig=fig_scatter,\n",
    "                                      df=plotting_df,\n",
    "                                      smiles_col='smiles',\n",
    "                                      title_col='group',\n",
    "                                      color_col='group')\n",
    "\n",
    "app_scatter.run_server(mode='inline', height=400)\n",
    "\n",
    "# the red points are the \"sampled\" molecules created from adding \"noise\" to the latent vectors of the\n",
    "# training data molecules.\n",
    "\n",
    "# Locate a red point and look at the training data points around it. You should be able to see some \n",
    "# structural similarities. One can think of the red point as a \"hybrid\" between its surrounding neighbours\n",
    "# of blue points\n",
    "\n",
    "# Note: it could be that sometimes \"close\" points are not that similar - this has to do with the \"smoothness\"\n",
    "#       of the latent space such that there are abrupt changes\n",
    "\n",
    "# Finally, if you want to see new molecules, re-run the cell above marked with \"RERUN HERE FOR NEW MOLECULES!\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ml_ruthenium_complexes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
