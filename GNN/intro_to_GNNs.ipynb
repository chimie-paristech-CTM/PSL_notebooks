{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cdc997b6-501f-464d-a388-bf3c9540400e",
      "metadata": {
        "id": "cdc997b6-501f-464d-a388-bf3c9540400e"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schwallergroup/ai4chem_course/blob/main/notebooks/03%20-%20Intro%20to%20Deep%20Learning/02_graph_nns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2361f4a6-2cc4-4347-aa21-f557e606bf6f",
      "metadata": {
        "id": "2361f4a6-2cc4-4347-aa21-f557e606bf6f"
      },
      "source": [
        "# Intro to Graph Neural Networks (GNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "179733c6",
      "metadata": {
        "id": "179733c6"
      },
      "source": [
        "### Relevant packages: Pytorch Geometric (PyG)\n",
        "PyG is a library built upon PyTorch to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to structured data. You can also browse its [documentation](https://pytorch-geometric.readthedocs.io/en/latest/) for additional details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "519f98ff",
      "metadata": {
        "id": "519f98ff"
      },
      "outputs": [],
      "source": [
        "# Install all libraries\n",
        "# CoLab has already preinstalled Pytorch for you\n",
        "! pip install pytorch-lightning wandb rdkit ogb\n",
        "# install PyG\n",
        "! pip install torch_geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d19b18b9",
      "metadata": {
        "id": "d19b18b9"
      },
      "source": [
        "Set a random seed to ensure repeatability of experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a55c1555",
      "metadata": {
        "id": "a55c1555"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Random Seeds and Reproducibility\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0465b86",
      "metadata": {
        "id": "a0465b86"
      },
      "source": [
        "### Molecular graph\n",
        "A [molecular graph](https://en.wikipedia.org/wiki/Molecular_graph) is a labeled graph whose nodes correspond to the atoms of the compound and edges correspond to chemical bonds. It also has node features (**atom features**), edge features (**bond features**) and graph labels (chemical properties of a molecule). Here, we demonstrate a simple example of building a molecular graph (undirected). Note that we do not consider hydrogen atoms as nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30bd3c57",
      "metadata": {
        "id": "30bd3c57"
      },
      "outputs": [],
      "source": [
        "from rdkit.Chem import MolFromSmiles\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "IPythonConsole.ipython_useSVG = True  # < use SVGs instead of PNGs\n",
        "IPythonConsole.drawOptions.addAtomIndices = True  # adding indices for atoms\n",
        "IPythonConsole.drawOptions.addBondIndices = False  # not adding indices for bonds\n",
        "IPythonConsole.molSize = 200, 200\n",
        "\n",
        "# N,N-dimethylformamide (DMF)\n",
        "dmf_smiles = 'CN(C)C=O'\n",
        "mol = MolFromSmiles(dmf_smiles)\n",
        "# show molecular graph of DMF, atom indices = node indices\n",
        "mol"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdcba6a2",
      "metadata": {
        "id": "fdcba6a2"
      },
      "source": [
        "### Atom features\n",
        "\n",
        "| feature | description |\n",
        "| ---- | ----  |\n",
        "| atom type  | atomic number |\n",
        "| degree  | number of directly-bonded neighbor atoms, including H atoms |\n",
        "| formal charge | integer electronic charge assigned to atom |\n",
        "| hybridization | sp, sp2, sp3, sp3d, or sp3d2 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37cab5a2",
      "metadata": {
        "id": "37cab5a2"
      },
      "outputs": [],
      "source": [
        "ATOM_FEATURES = {\n",
        "    'atom_type' : [1, 6, 7, 8, 9],  # elements: H, C, N, O, F\n",
        "    'degree' : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 'misc'],\n",
        "    'formal_charge' : [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 'misc'],\n",
        "    'hybridization' : [\n",
        "        'SP', 'SP2', 'SP3', 'SP3D', 'SP3D2', 'misc'\n",
        "        ],\n",
        "}\n",
        "\n",
        "def get_atom_fv(atom):\n",
        "    \"\"\"\n",
        "    Converts rdkit atom object to feature list of indices\n",
        "    :param atom: rdkit atom object\n",
        "    :return: list\n",
        "    \"\"\"\n",
        "    atom_fv = [\n",
        "        ATOM_FEATURES['atom_type'].index(atom.GetAtomicNum()),\n",
        "        ATOM_FEATURES['degree'].index(atom.GetTotalDegree()),\n",
        "        ATOM_FEATURES['formal_charge'].index(atom.GetFormalCharge()),\n",
        "        ATOM_FEATURES['hybridization'].index(str(atom.GetHybridization())),\n",
        "    ]\n",
        "    return atom_fv\n",
        "\n",
        "atom_fvs = [get_atom_fv(atom) for atom in mol.GetAtoms()]\n",
        "atom_fvs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12a4906b",
      "metadata": {
        "id": "12a4906b"
      },
      "source": [
        "### Bond features\n",
        "\n",
        "| feature | description |\n",
        "| ---- | ----  |\n",
        "| bond type  | single, double, triple, or aromatic |\n",
        "| stereo | none, any, E/Z or cis/trans |\n",
        "| conjugated  | whether the bond is conjugated |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03427568",
      "metadata": {
        "id": "03427568"
      },
      "outputs": [],
      "source": [
        "# Show indices of bonds\n",
        "IPythonConsole.drawOptions.addAtomIndices = False  # not adding indices for atoms\n",
        "IPythonConsole.drawOptions.addBondIndices = True  # adding indices for bonds\n",
        "mol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7f2f28",
      "metadata": {
        "id": "3f7f2f28"
      },
      "outputs": [],
      "source": [
        "BOND_FEATURES = {\n",
        "    'bond_type' : [\n",
        "        'SINGLE',\n",
        "        'DOUBLE',\n",
        "        'TRIPLE',\n",
        "        'AROMATIC',\n",
        "        'misc'\n",
        "    ],\n",
        "    'stereo': [\n",
        "        'STEREONONE',\n",
        "        'STEREOZ',\n",
        "        'STEREOE',\n",
        "        'STEREOCIS',\n",
        "        'STEREOTRANS',\n",
        "        'STEREOANY',\n",
        "    ],\n",
        "    'conjugated': [False, True],\n",
        "}\n",
        "\n",
        "def get_bond_fv(bond):\n",
        "    \"\"\"\n",
        "    Converts rdkit bond object to feature list of indices\n",
        "    :param bond: rdkit bond object\n",
        "    :return: list\n",
        "    \"\"\"\n",
        "    bond_fv = [\n",
        "        BOND_FEATURES['bond_type'].index(str(bond.GetBondType())),\n",
        "        BOND_FEATURES['stereo'].index(str(bond.GetStereo())),\n",
        "        BOND_FEATURES['conjugated'].index(bond.GetIsConjugated()),\n",
        "    ]\n",
        "    return bond_fv\n",
        "\n",
        "bond_fvs = [get_bond_fv(bond) for bond in mol.GetBonds()]\n",
        "bond_fvs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a42b4193",
      "metadata": {
        "id": "a42b4193"
      },
      "source": [
        "### Edge index\n",
        "In many cases, a list of paired node indices are used to describe edges rather than adjacency matrix. Here we use paired node indices (`edge_index`) with shape (2, num_edges) to define the edges in a graph.\n",
        "\n",
        "$$\n",
        "\\mathbf{E} = \\begin{bmatrix}\n",
        "    ..., & i, & ..., & j, & ... \\\\\n",
        "    ..., & j, & ..., & i, & ...\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "So, from the paired node indices list, we can conclude that there has an edge between node $i$ and node $j$ (undirected graph).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4291b9d",
      "metadata": {
        "id": "b4291b9d"
      },
      "outputs": [],
      "source": [
        "edge_index0, edge_index1 = [], []\n",
        "\n",
        "for bond in mol.GetBonds():\n",
        "    i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "    edge_index0 += [i, j]\n",
        "    edge_index1 += [j, i]\n",
        "\n",
        "edge_index = [edge_index0, edge_index1]\n",
        "edge_index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cbf2dbb",
      "metadata": {
        "id": "8cbf2dbb"
      },
      "source": [
        "### Molecular graph data\n",
        "\n",
        "We set the density of DMF(0.944 $g/cm^3$) as the graph feature (label). Here we use [Data](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html#torch_geometric.data.Data) class in `PyG` to create a graph data for DMF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bac3538d",
      "metadata": {
        "id": "bac3538d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# convert our data to tensors, which are used for model training\n",
        "x = torch.tensor(atom_fvs, dtype=torch.float)\n",
        "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
        "edge_attr = torch.tensor(bond_fvs, dtype=torch.float)\n",
        "y = torch.tensor([0.944], dtype=torch.float)\n",
        "\n",
        "dmf_data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "dmf_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b4e523",
      "metadata": {
        "id": "37b4e523"
      },
      "source": [
        "## Graph Neural Network\n",
        "\n",
        "A [graph neural network (GNN)](https://en.wikipedia.org/wiki/Graph_neural_network) is a class of artificial neural networks for processing data that can be represented as graphs. GNNs rely on [message passing methods](https://arxiv.org/abs/1704.01212), which means that nodes exchange information with the neighbors, and send \"messages\" to each other. Generally, GNNs operate in two phases: a **message passing** phase, which transmits information across the molecule to build a neural representation of the molecule, and a **readout** phase, which uses the final representation of the molecule to make predictions about the properties of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8de73f99",
      "metadata": {
        "id": "8de73f99"
      },
      "source": [
        "Here, we will define a GNN model using message passing neural network (MPNN) according to paper [\"Neural Message Passing for Quantum Chemistry\"](https://arxiv.org/abs/1704.01212). We just use [NNConv](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.NNConv.html#torch_geometric.nn.conv.NNConv) class to create message passing layers of our models (the various steps outlined in the lecture, i.e., 'send messages' + 'message aggregation' + 'node update' all happen under the hood inside this class). The [torch_geometric.nn](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html) module of PyG contains many different types of layers for message passing and readout, which can help us define GNN models more conveniently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f67d234a",
      "metadata": {
        "id": "f67d234a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import GRU\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import NNConv, MLP, global_add_pool\n",
        "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
        "\n",
        "\n",
        "class MPNN(pl.LightningModule):\n",
        "    def __init__(self, hidden_dim, out_dim,\n",
        "                 train_data, valid_data, test_data,\n",
        "                 std, batch_size=32, lr=1e-3):\n",
        "        super().__init__()\n",
        "        self.std = std  # std of data's target\n",
        "        self.train_data = train_data\n",
        "        self.valid_data = valid_data\n",
        "        self.test_data = test_data\n",
        "        self.batch_size = batch_size\n",
        "        self.lr = lr\n",
        "        # Initial layers\n",
        "        self.atom_emb = AtomEncoder(emb_dim=hidden_dim)\n",
        "        self.bond_emb = BondEncoder(emb_dim=hidden_dim)\n",
        "        # Message passing layers\n",
        "        nn = MLP([hidden_dim, hidden_dim*2, hidden_dim*hidden_dim])\n",
        "        self.conv = NNConv(hidden_dim, hidden_dim, nn, aggr='mean')\n",
        "        self.gru = GRU(hidden_dim, hidden_dim)\n",
        "        # Readout layers\n",
        "        self.mlp = MLP([hidden_dim, int(hidden_dim/2), out_dim])\n",
        "\n",
        "    def forward(self, data, mode=\"train\"):\n",
        "\n",
        "        # Initialization\n",
        "        x = self.atom_emb(data.x)\n",
        "        h = x.unsqueeze(0)\n",
        "        edge_attr = self.bond_emb(data.edge_attr)\n",
        "\n",
        "        # Message passing\n",
        "        for i in range(3):\n",
        "            m = F.relu(self.conv(x, data.edge_index, edge_attr))  # send message and aggregation\n",
        "            x, h = self.gru(m.unsqueeze(0), h)  # node update\n",
        "            x = x.squeeze(0)\n",
        "\n",
        "        # Readout\n",
        "        x = global_add_pool(x, data.batch)\n",
        "        x = self.mlp(x)\n",
        "\n",
        "        return x.view(-1)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Here we define the train loop.\n",
        "        out = self.forward(batch, mode=\"train\")\n",
        "        loss = F.mse_loss(out, batch.y)\n",
        "        self.log(\"Train loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # Define validation step. At the end of every epoch, this will be executed\n",
        "        out = self.forward(batch, mode=\"valid\")\n",
        "        loss = F.mse_loss(out * self.std, batch.y * self.std)  # report MSE\n",
        "        self.log(\"Valid MSE\", loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # What to do in test\n",
        "        out = self.forward(batch, mode=\"test\")\n",
        "        loss = F.mse_loss(out * self.std, batch.y * self.std)  # report MSE\n",
        "        self.log(\"Test MSE\", loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Here we configure the optimization algorithm.\n",
        "        optimizer = torch.optim.Adam(\n",
        "            self.parameters(),\n",
        "            lr=self.lr\n",
        "        )\n",
        "        return optimizer\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.valid_data, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_data, batch_size=self.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04593bf6",
      "metadata": {
        "id": "04593bf6"
      },
      "source": [
        "Here, we can use [InMemoryDataset]() class in PyG to create the graph dataset of ESOL conveniently. You can also browse its [tutorial](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html) and [pre-defined dataset](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html) to learn about how to create graph datasets quickly by PyG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f7eeec9",
      "metadata": {
        "id": "9f7eeec9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import (\n",
        "    Data,\n",
        "    InMemoryDataset,\n",
        "    download_url,\n",
        ")\n",
        "from ogb.utils import smiles2graph\n",
        "\n",
        "\n",
        "class ESOLGraphData(InMemoryDataset):\n",
        "    \"\"\"The ESOL graph dataset using PyG\n",
        "    \"\"\"\n",
        "    # ESOL dataset download link\n",
        "    raw_url = 'https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/delaney-processed.csv'\n",
        "\n",
        "    def __init__(self, root, transform=None):\n",
        "        super().__init__(root, transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['delaney-processed.csv']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['data.pt']\n",
        "\n",
        "    def download(self):\n",
        "        print('Downloading ESOL dataset...')\n",
        "        file_path = download_url(self.raw_url, self.raw_dir)\n",
        "\n",
        "    def process(self):\n",
        "        # load raw data from a csv file\n",
        "        df = pd.read_csv(self.raw_paths[0])\n",
        "        smiles = df['smiles'].values.tolist()\n",
        "        target = df['measured log solubility in mols per litre'].values.tolist()\n",
        "\n",
        "        # Convert SMILES into graph data\n",
        "        print('Converting SMILES strings into graphs...')\n",
        "        data_list = []\n",
        "        for i, smi in enumerate(tqdm(smiles)):\n",
        "\n",
        "            # get graph data from SMILES\n",
        "            graph = smiles2graph(smi)\n",
        "\n",
        "            # convert to tensor and pyg data\n",
        "            x = torch.tensor(graph['node_feat'], dtype=torch.long)\n",
        "            edge_index = torch.tensor(graph['edge_index'], dtype=torch.long)\n",
        "            edge_attr = torch.tensor(graph['edge_feat'], dtype=torch.long)\n",
        "            y = torch.tensor([target[i]], dtype=torch.float)\n",
        "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "            data_list.append(data)\n",
        "\n",
        "        # save data\n",
        "        torch.save(self.collate(data_list), self.processed_paths[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f352ca3",
      "metadata": {
        "id": "9f352ca3"
      },
      "source": [
        "Create, normalize and split ESOL graph dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c5d536d",
      "metadata": {
        "id": "9c5d536d"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Tuple\n",
        "import numpy as np\n",
        "from torch_geometric.data.dataset import Dataset\n",
        "\n",
        "\n",
        "class RandomSplitter(object):\n",
        "    \"\"\"Class for doing random data splits.\"\"\"\n",
        "\n",
        "    def split(\n",
        "        self,\n",
        "        dataset: Dataset,\n",
        "        frac_train: float = 0.7,\n",
        "        frac_valid: float = 0.1,\n",
        "        frac_test: float = 0.2,\n",
        "        seed: Optional[int] = None,\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Splits internal compounds randomly into train/validation/test.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset: Dataset\n",
        "          Dataset to be split.\n",
        "        seed: int, optional (default None)\n",
        "          Random seed to use.\n",
        "        frac_train: float, optional (default 0.8)\n",
        "          The fraction of data to be used for the training split.\n",
        "        frac_valid: float, optional (default 0.1)\n",
        "          The fraction of data to be used for the validation split.\n",
        "        frac_test: float, optional (default 0.1)\n",
        "          The fraction of data to be used for the test split.\n",
        "        seed: int, optional (default None)\n",
        "          Random seed to use.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
        "          A tuple of train indices, valid indices, and test indices.\n",
        "          Each indices is a numpy array.\n",
        "        \"\"\"\n",
        "        np.testing.assert_almost_equal(frac_train + frac_valid + frac_test, 1.0)\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "        num_datapoints = len(dataset)\n",
        "        train_cutoff = int(frac_train * num_datapoints)\n",
        "        valid_cutoff = int((frac_train + frac_valid) * num_datapoints)\n",
        "        shuffled = np.random.permutation(range(num_datapoints))\n",
        "        return (\n",
        "            shuffled[:train_cutoff],\n",
        "            shuffled[train_cutoff:valid_cutoff],\n",
        "            shuffled[valid_cutoff:],\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb4e4f8-86b4-4edd-998d-897d5eb02d2c",
      "metadata": {
        "id": "fdb4e4f8-86b4-4edd-998d-897d5eb02d2c"
      },
      "outputs": [],
      "source": [
        "# create dataset\n",
        "dataset = ESOLGraphData('./esol_pyg').shuffle()\n",
        "\n",
        "# Normalize target to mean = 0 and std = 1.\n",
        "mean = dataset.data.y.mean()\n",
        "std = dataset.data.y.std()\n",
        "dataset.data.y = (dataset.data.y - mean) / std\n",
        "mean, std = mean.item(), std.item()\n",
        "\n",
        "# split data\n",
        "splitter = RandomSplitter()\n",
        "train_idx, valid_idx, test_idx = splitter.split(dataset, frac_train=0.7, frac_valid=0.1, frac_test=0.2)\n",
        "train_dataset = dataset[train_idx]\n",
        "valid_dataset = dataset[valid_idx]\n",
        "test_dataset = dataset[test_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8ad21d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Here we create an instance of our GNN.\n",
        "# Play around with the hyperparameters!\n",
        "gnn_model = MPNN(\n",
        "    hidden_dim=64,\n",
        "    out_dim=1,\n",
        "    std=std,\n",
        "    train_data=train_dataset,\n",
        "    valid_data=valid_dataset,\n",
        "    test_data=test_dataset,\n",
        "    lr=0.001,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = 60)\n",
        "\n",
        "trainer.fit(model=gnn_model)\n",
        "\n",
        "# Now run test\n",
        "results = trainer.test(ckpt_path=\"best\")\n",
        "\n",
        "# Test RMSE\n",
        "test_mse = results[0][\"Test MSE\"]\n",
        "test_rmse = test_mse ** 0.5\n",
        "print(f\"\\nMPNN model performance: RMSE on test set = {test_rmse:.4f}.\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
